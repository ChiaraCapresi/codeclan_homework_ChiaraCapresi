---
title: "R Notebook"
output: html_notebook
---

```{r}
library(tidyverse)
library(CodeClanData)
```
# We start reading the file and assigning it to a variable 'books'!

```{r}
books <- read_csv("data/books.csv")
```
#Let's investigate the data file!

```{r}
view(books)
```

```{r}
dim(books)
```
This file has 11123 rows and 13 columns

Let's see which are exactly the columns names

```{r}
names(books)
```

# 1) The first thing I notice is the fact that there is a rowid column because the bookIDs have missing numbers.

```{r}
glimpse(books)
```
# Let's investigate missing values

```{r}
books %>% 
  summarise(na_rowid = sum(is.na(rowid)),
            na_bookID = sum(is.na(bookID)),
            na_title = sum(is.na(title)),
            na_authors = sum(is.na(authors)),
            na_average_rating = sum(is.na(average_rating)),
            na_isbn = sum(is.na(isbn)),
            na_isbn13 = sum(is.na(isbn13)),
            na_language_code = sum(is.na(language_code)),
            na_num_pages = sum(is.na(num_pages)),
            na_ratings_count = sum(is.na(ratings_count)),
            na_text_reviews_count = sum(is.na(text_reviews_count)),
            na_publication_date = sum(is.na(publication_date)),
            na_publisher = sum(is.na(publisher)),
    
  )
```
#2) There are no NAs!

The following should be a shorter way to check the same thing.


```{r}
books %>% 
  summarise(
    across(.col=names(books),
           .fns = ~sum(is.na(.x)))
  )
```
And the following is another...I am just making attempts XD


```{r}
books %>% 
  summarise(
    across(.col=everything(),
           .fns = ~sum(is.na(.x)))
  )
```


#Now I would like to check if there are zeros in any of the double columns, these could be considered unaccectable values and should be converted in NAs

```{r}
books_check <- books %>% 
  summarise(
           across(.col = is.double,
                  .fns = ~ mutate(.x = na_if(.x,0)))
  )

books_check %>% 
  summarise(
    across(.col = is.double,
           .fns = ~ sum(is.na(.x)))
  )
```
but...it doesn't wor :(....

```{r}
books %>% 
    mutate(ratings_count = na_if(ratings_count, 0))

#books2 %>% 
 # summarise(count_isbn = sum(is_na(isbn)))
  
```

```{r}
books_check <- books %>% 
    mutate(ratings_count = na_if(ratings_count, 0))  


books_check
  
```
```{r}
books_check %>% 
      summarise(na_ratings_count = sum(is.na(ratings_count)))

```



There are 80 books for which there are not ratings.

For this reason we should check is for any of those the average_rating is 0.00, otherwise, how could it be possible to make the average of 0 ratings?

First of all let's check how many 0.00 there are in the average_rating column.

```{r}
books_check <- books %>% 
  mutate(average_rating = na_if(average_rating, 0.00)) 

```
```{r}
books_check %>% 
    summarise(na_average_ratings=sum(is.na(average_rating)))

```
There are only 25 books with an average rating equal to zero!


Let's check the number of 0s in the other two numeric columns: 'ratings_count' and 'text_review_count'.

```{r}
books_check <- books %>% 
  mutate(
    across(.col=contains("count"),
         .fns = ~ na_if(.x, 0))
  )

books_check %>% 
  summarise(
    across(.col = contains("count"),
           .fns = ~ sum(is.na(.x)))
  )
```
Now we do the same check in a unique code. Of course many of the zero are already turned into NAs in the previous steps because I pasted on the same variable...but it's just for making attempts.


```{r}
books_check <- books %>% 
  mutate(
    across(.col = is.double,
         .fns = ~ na_if(.x, 0))
  )

books_check %>% 
  summarise(
    across(.col = is.double,
           .fns = ~ sum(is.na(.x)))
  )
```
This count the NAs in all the double columns. 

ELUCIDATION 1: this code gives also the 25 NAs of the average_rating because I turned before the '0.00' into NAs.

ELUCIDATION 2: It is not sure that we should consider any '0' or '0.00' value as an NA.

Let' s have a look of the 0s numbers in the columns.

POINT 1: We can consider NAs the 0s in the column 'num_pages' because it is not possible for a book to have 0 pages. Maybe we could fix a minimum number of pages...? However, let's start dropping out the rows corresponding to books with 0 pages.

# CLEANING_DATASET: I now introduce a variable 'books_clean' where I save all the changes I make for cleaning the data set.

# 3) Let's start with the column 'num_pages'.

```{r}
books_clean <- books %>% 
  mutate(num_pages = na_if(num_pages,0)) %>% 
  drop_na(num_pages)
```

Let's check if there are still NAs in num_pages

```{r}
books_clean %>% 
  mutate(num_pages = na_if(num_pages,0)) %>% 
  summarise(num_pages = sum(is.na(num_pages)))
```
Well done!

Now I would like to rename the 'rowid', 'bookID' and 'isbn13' columns in 'row_id', 'book_id' and 'isbn_13'.

Let's start seeing what the janitor library would do.

```{r}
library(janitor)
```

```{r}
books_clean <- books_clean %>% 
  clean_names()

books_clean
```
It x the second one but not the first because being 'rowid' in lowercase letters it doesn't recognise that thy are two words.


```{r}
books_clean <- books_clean %>% 
  rename("row_id" = "rowid", "isbn_13" = "isbn13") #Why the left element is the new?

books_clean
```


# 4) Let's speak about the other three numeric columns where appear the value 0 ('average_rating', 'ratings_count' and 'text_reviews_count').

The value 0 should be theoretically acceptable there. And I think we can for sure leave unchanged the zeros in the column 'text_count_review'.


Instead, I am not convinced about the ratio of the sums of 0 values in the other two columns ('average_rating' and 'ratings_count'). I think that there should be a sort of relation among the number of 0s in these two columns.

Just for recap, we discovered that there are 25 0s in 'average_rating' and 80 in 'ratings_count'.

My question is: how can have obtained an average of ratings greater than 0, books for which the number of ratings is 0? There are 55 books with this situation.

So, we could consider acceptable the '0.00's in the column 'average_rating' and all the 0s in the column 'ratings_count' that correspond to a null average of ratings. We should instead consider as NAs all the 0s in 'ratings_count' that correspond to an average of ratings greater than 0.


```{r}
prova <- books_clean %>% 
  select(ratings_count, average_rating) %>% 
  mutate(ratings_count = if_else(average_rating != 0.00,
      na_if(ratings_count, 0), average_rating))
```




```{r}
prova %>% 
  mutate(ratings_count = na_if(ratings_count,0)) %>% 
  summarise(ratings_count = sum(is.na(ratings_count)))
```


# OPS: There should be a MISTAKE because there are only 25 0.00s in 'average_rating'. 








# Let's investigate which are the 5 book with highest and smallest average rating 


```{r}
books_clean %>% 
  slice_min(average_rating, n=5) %>% 
  filter(average_rating == 0) %>% 
  summarise(average_rating = n()) 
```
There are 25 books with rating average = to 0.

```{r}
books_clean %>% 
  slice_min(average_rating, n=5) %>% 
  filter(average_rating == 0) %>% 
  select(title)
```
These are the titles.


```{r}
books_clean %>% 
  slice_max(average_rating, n=5) %>% 
  filter(average_rating == 5) %>% 
  summarise(average_rating = n()) %>% 
  pull()
```

There are 22 books with rating average = to 5.

```{r}
books_clean %>% 
  slice_max(average_rating, n=5) %>% 
  filter(average_rating == 5) %>% 
  select(title)
```
And these are their titles.


#HOMEWORK CORRECTION

# 1. How many books in each language?

```{r}
books %>% 
  
  group_by(language_code) %>% 
  summarise(num_of_books = n()) %>% 
  arrange(desc(num_of_books))
```


#2. Any similarities between top rated books?

```{r}
purged <- books %>% 
  #select(authors) %>% 
  filter(!authors == "NOT A BOOK")

purged %>% 
  filter(ratings_count >= 100) %>% 
  slice_max(average_rating, n=5) 
```


#3. Do more recently published books receive a higher review than older books?

```{r}
books %>% 
  filter(ratings_count > 1) %>% 
 # select(publication_date) %>% 
  select(title, authors, publication_date, average_rating) %>% 
  mutate(year = format(as.Date(publication_date, format = "%m/%d/%Y", "%Y"), .before = publication_date)) %>% 
  summarise(across(.cols = everything(), .fns = ~ sum(is.na(.x)))) %>% 
 mutate(age = case_when(
  year <2000 ~ "old",
  year >=2000 ~ "young"
), .after = year) %>% 
 # filter(is.na(year)) # there are 2 books that have NA for year, but publication date is like normal?!
  group_by(age) %>% 
  summarise(average_rating = mean(average_rating))
```


#4. Which languages has L.K. Rowling published in?

```{r}
books %>% 
  select(authors, publication_date, language_code) %>% 
  mutate(JK = str_detect(authors,"J.K. Rowling"), .after = authors) %>% 
  filter(JK == TRUE) %>% 
  distinct(language_code)
```


#5. Are there missing values in the data?

```{r}
books %>% 
  summarise(across(.cols = everything(), .fns = ~ sum(is.na(.x))))
```


