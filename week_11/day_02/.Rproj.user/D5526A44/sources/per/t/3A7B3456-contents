---
title: "Chiara homework week 11 day 2"
output: html_notebook
---


```{r}
library(rpart)
library(rpart.plot)
library(tidyverse)

library(tidyverse)
titanic_set <- read_csv('data/titanic_decision_tree_data.csv')

shuffle_index <- sample(1:nrow(titanic_set))

# shuffle the data so class order isn't in order - need this for training/testing split later on 
titanic_set <- titanic_set[shuffle_index, ]



```


# MVP

## QAuestion 1

Cleaning up the data is always the first step. Do the following:

  

```{r}
skimr::skim(titanic_set)
glimpse(titanic_set)
```


-  Take only observations which have a survived flag (i.e. that aren’t missing)

```{r}
titanic_clean <- titanic_set %>% 
  filter(!is.na(survived))
```
  

-  Turn your important variables into factors (sex, survived, pclass, embarkation)

```{r}
#titanic_clean <- titanic_clean %>% 
# mutate(across(.col = c("sex", "survived", "pclass", "embarked"), .fns = ~as.factor(.x)))
```



  -  Create an age_status variable which groups individuals under (and including) 16 years of age into a category called “child” category and those over 16 into a category called “adult”
  
  -  Drop the NA
  -  Drop any variables you don’t need (X1, passenger_id, name, ticket, far, cabin)



```{r}
titanic_clean <- titanic_clean %>% 
mutate(sex = as.factor(sex), 
           age_status = as.factor(if_else(age <= 16, "child", "adult")),  # the NAS?????
         class = factor(pclass, levels = c(3,2,1), labels = c("Lower", "Middle", "Upper")), 
           survived_flag = factor(survived, levels = c(0,1), labels = c("No", "Yes")), 
           port_embarkation = as.factor(embarked)) %>%
  select(sex, age_status, class, port_embarkation, sib_sp, parch, survived_flag) %>%
  na.omit()
```


## Question 2


Have a look at your data and create some plots to ensure you know what you’re working with before you begin. Write a summary of what you have found in your plots. Which variables do you think might be useful to predict whether or not people are going to die? Knowing this before you start is the best way to have a sanity check that your model is doing a good job.

```{r}
library(GGally)
```


```{r}
ggpairs(titanic_clean, progress = FALSE)
```

`sex` and `class` seems to be the features that most influence the `survived_flag`. Even if it seems to be interesting to consider also the `age_status`.



## Question 3

Now you can start to build your model. Create your testing and training set using an appropriate split. Check you have balanced sets. Write down why you chose the split you did and produce output tables to show whether or not it is balanced. [Extra - if you want to force balanced testing and training sets, have a look at the stratified() function in package splitstackshape (you can specify multiple variables to stratify on by passing a vector of variable names to the group argument, and get back testing and training sets with argument bothSets = TRUE)]


```{r}
dim(titanic_clean)
```



```{r}
#set.seed(19)

#how many rows in total

n_data <- nrow(titanic_clean)

#create a test sample index
test_index <- sample(1:n_data, size = n_data*0.1)

# split the data
titanic_test <- slice(titanic_clean, test_index)
titanic_train <- slice(titanic_clean, -test_index)


?set.seed
```



I choose a split of 90-10 since the cleaned dataset contains 712 rows, which seems to me to be a not so much high number!



```{r}
titanic_test %>% 
  janitor::tabyl(survived_flag)
```
```{r}
titanic_train %>% 
  janitor::tabyl(survived_flag)
```

The tables seems to have quite similar values, so I conclude that the split I did is quite proportionate.



## Question 4

Create your decision tree to try and predict survival probability using an appropriate method, and create a decision tree plot.

```{r}
# 1. make tree model

titanic_fit <- rpart(
  formula = survived_flag ~., #include all variables
  data = titanic_clean,
  method = "class" # for a categorical predictor
)

# 2. plot tree model

rpart.plot(titanic_fit,
           yesno = 2, # this writes yes/no at all splits
           type = 2, #dictates where our conditions lie at each node
           fallen.leaves = TRUE, # TRUE means leaves all alligned at bottom
           faclen = 6, #length of factor names
           digits = 2, # how many decimal places is prob reported in
           split.border.col = 1 #colour 
           )

```

I used the method `class` since `survived_flag` is categorical.

## Question 5

Write down what this tells you, in detail. What variables are important? What does each node tell you? Who has the highest chance of surviving? Who has the lowest? Provide as much detail as you can.


- First of all, the variables it has picked, which should be the most informative are:`sex`, `class`, `sib_sp` and `port_embarkation`.

- If we look at all the data, the most likely result is `not survived`.

- The chance of surviving, considering all the features is `0.40`.

- `males` has 0,21 probability to `survive`, and died for the `64%`.

- `females` has 0.75 probability to `survive` and died for the `36%`.

- If the passenger are females, then the class is determinant: 

  - if the class is `lower`, then the probability of `survive` is 0.46 and died for 14%
  - if the class is not `lower` then the probablility of `survive` is 0.94 and died for 22%.

## Question 6

Test and add your predictions to your data. Create a confusion matrix. Write down in detail what this tells you for this specific dataset.


```{r}
titanic_pred <- titanic_test %>% 
 add_predictions(titanic_fit, type = 'class')
```



```{r}
titanic_pred %>%
              conf_mat(truth = survived_flag, estimate = pred)
```


```{r}
accuracy <- titanic_pred %>%
 accuracy(truth = survived_flag, estimate = pred)

accuracy 
```

The .estimate column in the output shows the probability of correctly predicting whether a character in the test set died or not, it is 83%, which is good!

```{r}
sensitivity <- titanic_pred %>%
 sensitivity(truth = survived_flag, estimate = pred)

sensitivity 
```


```{r}
specificity <- titanic_pred %>%
 specificity(truth = survived_flag, estimate = pred)

specificity 
```

















































































